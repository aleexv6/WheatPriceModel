{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f734ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../\")) #vscode import \n",
    "\n",
    "from settings.settings import USDA_NASS_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212f423",
   "metadata": {},
   "source": [
    "Export sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03610934",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://apps.fas.usda.gov/export-sales/h107.htm').text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "table = soup.find('table')\n",
    "\n",
    "rows = []\n",
    "for tr in table.find_all(\"tr\"):\n",
    "    cells = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "    rows.append(cells)\n",
    "\n",
    "cols = []\n",
    "for i, j in zip(rows[1], rows[2]):\n",
    "    if f\"{i} {j}\" not in cols:\n",
    "        cols.append(f\"{i} {j}\")\n",
    "    else:\n",
    "        cols.append(f\"NMY {i} {j}\")\n",
    "\n",
    "data = rows[4:]\n",
    "df = pd.DataFrame(data, columns=cols)\n",
    "df = df.dropna()\n",
    "df.to_csv('../../data/US_export_sales/export_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0358c30b",
   "metadata": {},
   "source": [
    "Crop progress / condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ebf0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(category):\n",
    "    endpoint = f\"https://quickstats.nass.usda.gov/api/api_GET/?key={USDA_NASS_API_KEY}\"\n",
    "    request_params = f\"source_desc=SURVEY&sector_desc=CROPS&group_desc=FIELD CROPS&commodity_desc=WHEAT&statisticcat_desc={category}\" \\\n",
    "                    \"&agg_level_desc=NATIONAL&class_desc=WINTER\" \\\n",
    "                    \"&format=JSON\"\n",
    "\n",
    "    url = '&'.join([endpoint, request_params])\n",
    "\n",
    "    r = requests.get(url)\n",
    "    df = pd.DataFrame(r.json()['data'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30d0d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = download_data('CONDITION')\n",
    "progress = download_data('PROGRESS')\n",
    "\n",
    "conditions.to_csv('../../data/crop_progress/conditions.csv', index=False)\n",
    "progress.to_csv('../../data/crop_progress/progress.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff435ba2",
   "metadata": {},
   "source": [
    "Rivers Water Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beac314",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_dict = {\n",
    "    \"Mississippi River at St. Louis, MO\": \"USGS-07010000\",\n",
    "    \"Ohio River at Cincinnati, OH\": \"USGS-03255000\",\n",
    "    \"Illinois River at Meredosia, IL\": \"USGS-05585500\",\n",
    "    \"Ohio River at Louisville, KY\": \"USGS-03294500\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_rivers(location_id):    \n",
    "    url =  \"https://api.waterdata.usgs.gov/ogcapi/v0/collections/daily/items?f=json&lang=en-US&limit=50000&skipGeometry=false&sortby=time&offset=0&\" \\\n",
    "          f\"monitoring_location_id={location_id}&parameter_code=00065\"\n",
    "    r = requests.get(url)\n",
    "    data = r.json()['features']\n",
    "    data_list = [d['properties'] for d in data]\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "621f50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for k, v in location_dict.items():\n",
    "    df = download_rivers(v)\n",
    "    df['location'] = k\n",
    "    data_list.append(df)\n",
    "rivers = pd.concat(data_list)\n",
    "\n",
    "rivers.to_csv('../../data/rivers/rivers_gage_height.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a223d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
